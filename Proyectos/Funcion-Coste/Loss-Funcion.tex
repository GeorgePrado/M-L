\documentclass[utf8,spanish,xcolor={table,dvipsnames},12pt]{beamer}
\uselanguage{spanish}
\languagepath{spanish}

\usepackage{dsfont}

\title[Función de Coste]{Función de  Coste}
\subtitle{Tópicos de Investigación : Machine Learning}
\author{Josué Lucero Rivera}
\institute[UNI]{Universidad Nacional de Ingeniería}
\date{29 de Setiembre}

\usetheme{Berlin}
\useinnertheme{rectangles}
\useoutertheme{infolines}
%\usecolortheme{wolverine}
%\usefonttheme[onlymath]{serif} %%% SOLO MATEMATICA SE MANTIENE

\begin{document}

\begin{frame}
\maketitle
\end{frame}


\begin{frame}
Deseamos encontrar una función: $f:X\rightarrow \mathds{R}$ tal que para $(x,y) \in X\times Y$ el valor $f(x)$ es una buena predicción de $y$ a $x$. La siguiente definición nos ayudará a definir lo que entendemos por \textit{buena predicción}.
\end{frame}


\begin{frame}
\begin{block}{Definición:}
 Sea $(X,\mathcal{A})$ un espacio medible, y $Y\subset\mathds{R}$ un subconjunto cerrado. Entonces la función $L : X\times Y\times \mathds{R} \rightarrow [0,\infty\rangle$ es llamada una \textbf{función de coste}, o simplemente de \textbf{coste}, si es medible.
\end{block}
Interpretaremos $L(x,y,f(x))$ como el \textit{costo}, de predicción $y$ por $f(x)$ si $x$ es observado, es decir, cuanto menor es el valor $L(x,y,f(x))$,  $f(x)$ que predice $y$ en el sentido de $L$.

\vspace{0.2cm}

Recordemos ahora desde la introducción que nuestro principal objetivo es tener un  Coste medio de las observaciones futuras $(x,y)$ que no se ven. Esto conduce a la siguiente definición.
\end{frame}


\begin{frame}
\begin{block}{Definición:}
Sea $L : X\times Y\times \mathds{R} \rightarrow [0,\infty\rangle$ una función de Coste, y $P$ una medida de probabilidad en $X\times Y$. Entonces, para una función medible $f: X\rightarrow  \mathds{R}$, el $L$-\textbf{riesgo} es definido por:

    \begin{align*}
    R_{L,P}(f) & = \int\limits_{X\times Y}L(x,y,f(x))dP(x,y)\\
     & =\int\limits_{X}\int\limits_{Y}L(x,y,f(x))dP(y|x)dP_{X}(x)
    \end{align*}
\end{block}
\end{frame}


\begin{frame}
	


Para una sucesión dada $D=((x_{1},y_{1}),\ldots,(x_{n},y_{n})\in (X\times Y)^{n}$, escribimos $D=\frac{1}{n}\sum_{i=1}^{n}\delta_{(x_{i},y_{i})}$, donde $\delta_{(x_{i},y_{i})}$ es la medida de Dirac en $(x_{i},y_{i})$.

\vspace{0.2cm}

 En otras palabras, $D$ es la medida empírica asociada a $D$. 
 
 \vspace{0.2cm}
 
 El riesgo de la función $f: X\rightarrow\mathds{R}$ con respecto a esta medida es llamado el \textbf{$L$-riesgo empírico}

$$R_{L,D}(f)=\frac{1}{n}\sum_{i=1}^{n}L(x_{i},y_{i},f(x_{i}))$$
\end{frame}


\begin{frame}
\begin{block}{Definición:}
Sea $L: X\times Y \times \mathds{R} \rightarrow [0,\infty\rangle$ una función de Coste y $P$ una medida de probabilidad en $X\times Y$. El $L$-riesgo minimal
  $$R^{\ast}_{L,P}=\inf\{R_{L,P}(f) \hspace{0.1cm} |\hspace{0.1cm} f: X\rightarrow \mathds{R} \hspace{0.1cm} es \hspace{0.1cm} medible\}$$
  es llamado el \texttt{riesgo de Bayes} con respecto a $P$ y $L$.
  
 \vspace{0.2cm}
 
  Además, una función medible $f^{\ast}_{L,P} : x\rightarrow \mathds{R}$ con $R_{L,P}(f^{\ast}_{L,P})$ es llamada una \textbf{función de decisión de Bayes}.
\end{block}
\end{frame}


\begin{frame}
Por lo general, el primer paso para resolver un problema de aprendizaje práctico es encontrar una función de de Coste que mejor describe el aprendizaje.

\vspace{0.3cm}

 En general, la elección de una función  de Coste adecuado depende de una aplicación específica. Sin embargo, hay algunos escenarios básicos de aprendizaje que a menudo se ajustan al problema de aprendizaje,
 
 \vspace{0.2cm}
 
 Veamos unos ejemplos:
\end{frame}


\begin{frame}{Clasificación Binaria}
Sean $Y=\{-1,1\}$ y $P$ una distribución que genera datos desconocidos en $X\times Y$. Entonces, la meta en clasificación binaria es predecir $y$ del par $(x,y)$ trazada desde $P$ si solo $x$ es observado.

\vspace{0.3cm}


La función de  Coste más común que describe esta meta de aprendizaje es la \textbf{clasificación de de Coste}

\vspace{0.2cm}

 $L_{class}: Y\times \mathds{R} \rightarrow [0,\infty\rangle$, que es definida por
\begin{center}
  $L_{class}(y,t)=\boldsymbol{1_{\langle -\infty, 0]}}(y \ sign \ t)$, \hspace{1cm} $y\in Y, t\in \mathds{R}$
\end{center}
donde utilizamos la convención sign 0:=1.
\end{frame}


\begin{frame}
Notamos que $L_{class}$ solo penaliza predicciones $t$ cuyo signos son contrarios a los de $y$, por lo que de hecho refleja nuestro objetivo de aprendizaje. Ahora, sea una función medible $f: X\rightarrow \mathds{R}$, unos cálculos simples nos muestran:

\begin{align*}
    R_{L_{class},P}(f) & =\int_{X} \eta(x)\boldsymbol{1_{\langle -\infty, 0]}}(f(x))+\boldsymbol{1_{\langle 0, -\infty]}}(f(x))dP_{X}(x)\\
     & = P(\{(x,y)\in X\times Y \ sign \ f(x)\neq y \})
\end{align*}

donde $\eta(x):= P(y = 1|x)$, $x\in X$.
\end{frame}


\begin{frame}
De esto podemos concluir que $f$ es una función de decisión de Bayes si y sólo si $(2\eta(x)-1)$ sign $f(x)\geq0$ para $P_{X}$ c.t.p. $x\in X$. Además esta consideración nos da

$$R^{\ast}_{L_{class},P}=\int_{X} \min\{\eta, 1-\eta\}dP_{X}$$
\end{frame}


\begin{frame}{Observaciones :}
La función de Coste $L_{class}$ iguala los pesos de ambos tipos de errores, a saber $y=1$ cuando $f(x)<0$, y $y=-1$ cuando $f(x)\geq0$. Esto tiene sentido especialmente en situaciones en las que se desea clasificar objetos tales como caracteres escritos a mano o imágenes.

\vspace{0.2cm}

 En muchas situaciones prácticas, sin embargo, ambos tipos de error deben ser objeto de ponderaciones diferentes. Por ejemplo, si se quiere detectar intrusiones en la red informática, en función de los recursos disponibles para la investigación de las alarmas y la sensibilidad de la red, los dos tipos de errores es probable que tengan diferentes costes reales.
\end{frame}

\begin{frame}{Clasificación Binaria Ponderada}
Sea $Y={-1,1}$ y $\alpha \in \langle 0,1 \rangle$. Entonces la \textbf{$\alpha$-de Coste de clasificación ponderada} $L_{\alpha -class}:Y\times\mathds{R}\rightarrow[0,\infty \rangle$ es definida por:

$$L_{\alpha -class}=\begin{cases}
                             1-\alpha, & \mbox{si } y=-1, t<0 \\
                             \alpha, & \mbox{if } y=-1,t\geq0 \\
                             0, & \mbox{en otro caso}.
                           \end{cases}$$
para todo $y\in Y$, $t\in\mathds{R}$.
\end{frame}


\begin{frame}
Es evidente que tenemos $2L_{\frac{1}{2}-class}=L_{class}$, es decir, la clasificación binaria estándar es un caso especial de la clasificación general ponderada. 

\vspace{0.2cm}

Ahora, tenemos la medida de probabilidad $P$ en $X\times Y$ y un medible $f:X\rightarrow\mathds{R}$, el $L_{\alpha-class}$-riesgo puede ser calculado por:

$$R_{L_{\alpha-class},P}(f)=(1-\alpha)\int_{f<0}\eta dP_{X}+\alpha\int_{f\geq0}(1-\eta)dP_{X}$$

Dónde $\eta(x)=P(y=1|x)$, $x\in X$.
\end{frame}


\begin{frame}
 De esto concluimos que $f$ es una función de decisión de Bayes si y sólo si $(\eta(x)-\alpha) sign\  f(x)\geq0$ para $P_{X}$- casi todo punto $x\in X$.
 
\vspace{0.2cm}


Finalmente, el $L_{\alpha-class}$-riesgo de Bayes es

$$R^{\ast}_{L_{\alpha-class},P}=\int_{X}\min \{(1-\alpha)\eta,\alpha(1-\eta)\}dP_{X}$$

En este ejemplo la meta es predecir $y$ a partir del conjunto $\{-1,1\}$.
\end{frame}


\begin{frame}{Regresión de mínimos cuadrados}
La meta en regresión es predecir $y\in Y=\mathds{R}$ del par $(x,y)$ a partir de una medida de probabilidad desconocida $P$ en $X\times Y$ si observamos solo $x$. 

\vspace{0.2cm}

 La forma más común de formalizar esta meta está basada en la f\'ormula  \textbf{de Coste mínima cuadrada} $L_{LS}:Y\times \mathds{R}\rightarrow[0,\infty\rangle$ definida por

$$L_{LS}(y,t)=(y-t)^{2}, \hspace{2cm} y\in Y, t\in \mathds{R}$$
\end{frame}


\begin{frame}
En otras palabras, la fórmula de Coste mínima cuadrada minimiza el  coste cuadrático entre $y$ y $t$. Evidentemente para cada función medible $f:X\rightarrow\mathds{R}$, el $L_{LS}$-riesgo es

$$R_{L_{LS},P}=\int_{X}\int_{Y}(y-f(x))^{2}dP(y|x)dP_{X}(x)$$

\vspace{0.2cm}

y sólo si $f(x)$ es casi igual a $Y$ evaluado en $x$, es decir, si y sólo si:

$$f(x)=\mathds{E}_{P}(Y|x)=\int_{Y}dP(y|x)$$

Para $P_{X}$ en casi todo punto $x\in X$.
\end{frame}


\begin{frame}
Para minimizar la integral interior respecto de $f(x)$, tenemos que tener en cuenta que $f$ es una función de decisión de Bayes si y sólo si $f(x)$ es casi igual a $Y$ evaluado en $x$, es decir, si y sólo si:

$$f(x)=\mathds{E}_{P}(Y|x)=\int_{Y}dP(y|x)$$

Para $P_{X}$ en casi todo punto $x\in X$.

\vspace{0.2cm}

Además, si hacemos $x\mapsto \mathds{E}_{P}(Y|x)$ en $R_{L_{LS},P}(\cdot)$ muestra que el $L_{LS}$- riesgo de Bayes es el promedio condicional $Y$- varianza, es decir,

$$R^{\ast}_{L_{LS},P}=\int_{X}\mathds{E}_{P}(Y^{2}|x)-(\mathds{E}_{P}(Y|x))^{2}dP_{x}(x)$$
\end{frame}


\begin{frame}
Finalmente, un cáculo básico muestra que el $L_{LS}$-riesgo de $\textit{exceso}$ de $f:X\rightarrow\mathds{R}$ es

$$R_{L_{LS}}(f)-R^{\ast}_{L_{LS},P}=\int_{X}(\mathds{E}_{P}(Y|x)-f(x))^{2}dP_{X}(x)$$

Es decir, si $R_{L_{LS},P}(f)$ está cerca de $R^{\ast}_{L_{LS},P}$, entonces $f$ está cerca de una función de decisión de Bayes en el sentido de la $\|\cdot\|_{L_{2}(P_{X})}$
\end{frame}


\begin{frame}{Bibliografía}
\begin{thebibliography}{9}

\bibitem{Kop04}
Duchi, Jhon
\newblock{\em Supplemental Lecture notes}.
\newblock Stanford CS 229


\bibitem{Ber04}
Berger, James
\newblock{\em Statistical Decision Theory and Bayesian Analysis}. 2th ed.
\newblock Springer Verlag
\end{thebibliography}
\end{frame}


\end{document} 