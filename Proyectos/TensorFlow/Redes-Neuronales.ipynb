{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales\n",
    "\n",
    "Nombre: Carlos Antonio Cueva Rojas\n",
    "Código: 20124118H\n",
    "\n",
    "## Conceptos\n",
    "\n",
    "### Corteza visual\n",
    "La corteza visual primaria es el área visual más estudiada del cerebro, está localizada en el polo posterior de la corteza occipital (la corteza occipital es responsable del procesamiento de los estímulos visuales). Es la más simple, temprana área visual cortical. Esta altamente especializada en el procesamiento de información acerca de los objetos estáticos y en movimiento y es excelente en el manejo de reconocimiento de patrones.\n",
    "\n",
    "* Su función basicamente se inferir en  los impulsos provenientes de la retina e ingresarlo a las demás zonas de la corteza cerebral.\n",
    "\n",
    "### Redes neuronales convolucionales\n",
    "\n",
    "Una red neuronal convolucional es un tipo de red neuronal artificial donde las neuronas corresponden a campos receptivos de una manera muy similar a las neuronas en la corteza visual primaria $(V_1)$ de un cerebro biológico. Este tipo de red es una variación de un perceptron multicapa, pero su funcionamiento las hace mucho más efectivas para tareas de visión artificial, especialmente en la clasificación de imágenes.\n",
    "\n",
    "\n",
    "Los modelos de perceptrón multicapa tradicionales MLP fueron utilizados con éxito para el reconocimiento de la imagen, debido a la conectividad completa entre los nodos que sufren de la maldición de la dimensionalidad y por lo tanto no escala bien a las imágenes de mayor resolución.\n",
    "\n",
    "Por ejemplo, en CIFAR-10, las imágenes son sólo de tamaño $32\\times 32\\times3$ ($32$ de ancho, $32$ de alto, $3$ canales de color), por lo que una sola neurona totalmente conectado en una primera capa oculta de una red neuronal regular tendría $32 * 32 * 3 = 3,072$ pesos. Una imagen de $200\\times 200$, sin embargo, conduciría a neuronas que tienen $200 * 200 * 3 = 120.000$ pesos.\n",
    "\n",
    "Dicha arquitectura de red no tiene en cuenta la estructura espacial de los datos, tratando los píxeles de entrada que están muy separados entre sí y están exactamente juntos en exactamente la misma base. Claramente, la conectividad total de las neuronas es un desperdicio en el marco del reconocimiento de la imagen, y el gran número de parámetros rápidamente conduce a la superposición.\n",
    "\n",
    "Las redes neuronales convolucionales son variantes biológicamente inspiradas de perceptrones multicapa, diseñadas para emular el comportamiento de una corteza visual. Estos modelos mitigan los desafíos planteados por la arquitectura MLP aprovechando la fuerte correlación espacialmente local presente en las imágenes naturales. A diferencia de las MLP, CNN tiene las siguientes características distintivas:\n",
    "\n",
    "1- Volúmenes 3D de neuronas. Las capas de una CNN tienen neuronas dispuestas en 3 dimensiones: anchura, altura y profundidad. Las neuronas dentro de una capa sólo están conectadas a una pequeña región de la capa anterior, llamada campo receptivo. Distintos tipos de capas, tanto locales como completamente conectadas, se apilan para formar una arquitectura CNN.\n",
    "\n",
    "2- Conectividad local: siguiendo el concepto de campos receptivos, las CNN explotan la correlación espacialmente local mediante la aplicación de un patrón de conectividad local entre neuronas de capas adyacentes. La arquitectura asegura así que los \"filtros\" aprendidos produzcan la respuesta más fuerte a un patrón de entrada espacialmente local. El apilado de muchas de estas capas conduce a \"filtros\" no lineales que se vuelven cada vez más \"globales\" (es decir, responden a una región mayor de espacio de píxeles). Esto permite que la red primero cree buenas representaciones de pequeñas partes de la entrada, luego ensamble representaciones de áreas más grandes de ellas.\n",
    "\n",
    "3- Pesos compartidos: En CNNs, cada filtro se reproduce en todo el campo visual. Estas unidades replicadas comparten la misma parametrización (vector de peso y sesgo) y forman un mapa de características. Esto significa que todas las neuronas en una capa convolucional dada detectan exactamente la misma característica. De este modo, las unidades de replicación permiten detectar las características independientemente de su posición en el campo visual, constituyendo así la propiedad de la invariancia de la traducción.\n",
    "\n",
    "\n",
    "Juntas, estas propiedades permiten que las redes neuronales convolucionales logren una mejor generalización en problemas de visión. El reparto de peso también ayuda a reducir drásticamente el número de parámetros libres que se están aprendiendo, reduciendo así los requisitos de memoria para ejecutar la red. La reducción de la huella de memoria permite el entrenamiento de redes más grandes y más potentes.\n",
    "\n",
    "###  Bloques de construcción\n",
    "\n",
    "\n",
    "Una arquitectura CNN está formada por una pila de capas distintas que transforman el volumen de entrada en un volumen de salida (por ejemplo, la retención de las puntuaciones de clase) a través de una función diferenciable. Se utilizan comúnmente algunos tipos distintos de capas. Los discutimos más adelante:\n",
    "\n",
    "1 . Capa convolucional\n",
    "\n",
    " La capa convolucional es el componente básico de una CNN. Los parámetros de la capa consisten en un conjunto de filtros (o núcleos) que pueden ser aprendidos, que tienen un campo receptivo pequeño, pero que se extienden a través de toda la profundidad del volumen de entrada. Durante el paso hacia delante, cada filtro es convolucionado a través de la anchura y altura del volumen de entrada, calculando el producto punto entre las entradas del filtro y la entrada y produciendo un mapa de activación bidimensional de ese filtro. Como resultado, la red aprende filtros que se activan cuando ven algún tipo específico de característica en alguna posición espacial en la entrada.\n",
    " \n",
    "Apilar los mapas de activación de todos los filtros a lo largo de la dimensión de profundidad forma el volumen de salida completo de la capa de convolución. Por lo tanto, cada entrada en el volumen de salida puede ser interpretada como una salida de una neurona que mira una pequeña región en la entrada y comparte parámetros con neuronas en el mismo mapa de activación.\n",
    "\n",
    "1.1 . Conectividad local\n",
    "\n",
    "\n",
    "Cuando se trata de entradas de alta dimensión, tales como imágenes, no es práctico conectar las neuronas a todas las neuronas en el volumen anterior porque tal arquitectura de red no toma en cuenta la estructura espacial de los datos. Las redes convolucionales explotan la correlación espacial local mediante la aplicación de un patrón de conectividad local entre neuronas de capas adyacentes: cada neurona está conectada a sólo una pequeña región del volumen de entrada. El alcance de esta conectividad es un hiperparámetro llamado campo receptivo de la neurona. Las conexiones son locales en el espacio (a lo largo del ancho y la altura), pero siempre se extienden a lo largo de toda la profundidad del volumen de entrada. Esta arquitectura asegura que los filtros aprendidos produzcan la respuesta más fuerte a un patrón de entrada espacialmente local.\n",
    "\n",
    "1.2 . Disposición espacial\n",
    "\n",
    "\n",
    "Tres hiperparámetros controlan el tamaño del volumen de salida de la capa convolucional: la profundidad, el paso y el relleno cero.\n",
    "\n",
    "- La profundidad del volumen de salida controla el número de neuronas de la capa que se conectan a la misma región del volumen de entrada. Todas estas neuronas aprenderán a activarse para diferentes características en la entrada. Por ejemplo, si la primera capa convolucional toma la imagen cruda como entrada, entonces diferentes neuronas a lo largo de la dimensión de profundidad pueden activarse en presencia de varios bordes orientados o manchas de color.\n",
    "\n",
    "- El paso  controla cómo se asignan las columnas de profundidad alrededor de las dimensiones espaciales (ancho y alto). Cuando el paso  es 1, una nueva columna de profundidad de neuronas se asigna a posiciones espaciales sólo 1 unidad espacial aparte. Esto conduce a campos receptivos muy solapados entre las columnas, y también a grandes volúmenes de salida. Por el contrario, si se usan pasos mayores, entonces los campos receptivos se superpondrán menos y el volumen de salida resultante tendrá dimensiones espaciales más pequeñas.\n",
    "\n",
    "- A veces es conveniente colocar la entrada con ceros en el borde del volumen de entrada. El tamaño de este relleno cero es un tercer hiperparámetro. El relleno cero  proporciona control del tamaño del volumen de salida espacial. En particular, a veces es deseable preservar exactamente el tamaño espacial del volumen de entrada.\n",
    "\n",
    "El tamaño espacial del volumen de salida se puede calcular como una función del tamaño de volumen de entrada W , el tamaño del campo del núcleo de las neuronas de la capa de convección K , el paso con el que se aplican S , y la cantidad de relleno cero P usado en el borde. La fórmula para calcular cuántas neuronas \"encajan\" en un volumen dado viene dada por $(W - K + 2 P)$ . Si este número no es un número entero, los pasos se establecen incorrectamente y las neuronas no se pueden mosaizar para encajar en el volumen de entrada de una manera simétrica. En general, establecer el relleno cero para que sea $P = (K - 1) / 2$  cuando la zancada es $S = 1$ asegura que el volumen de entrada y el volumen de salida tendrán el mismo tamaño espacialmente. Aunque generalmente no es completamente necesario usar todas las neuronas de la capa anterior, por ejemplo, puede decidir usar sólo una porción de relleno.\n",
    "\n",
    "\n",
    "\n",
    "1.3 .Compartición de parámetros\n",
    "\n",
    "\n",
    "El esquema de compartición de parámetros se utiliza en capas convolucionales para controlar el número de parámetros libres. Se basa en una suposición razonable: que si una característica de parche es útil para calcular en alguna posición espacial, entonces también debería ser útil calcular en una posición diferente. En otras palabras, denota una sola rebanada de profundidad bidimensional como un trozo de profundidad, limitamos las neuronas en cada rebanada de profundidad para usar los mismos pesos y sesgos.\n",
    "\n",
    "\n",
    "Puesto que todas las neuronas en una sola porción de la profundidad están compartiendo la misma parametrización, entonces el paso delantero en cada rebanada de la profundidad de la capa de CONV se puede calcular como una convolución de los pesos de la neurona con el volumen de entrada (de ahí el nombre: capa convolucional). Por lo tanto, es común referirse a los conjuntos de pesos como un filtro (o un kernel), que se convoluciona con la entrada. El resultado de esta convolución es un mapa de activación, y el conjunto de mapas de activación para cada filtro diferente se apilan a lo largo de la dimensión de profundidad para producir el volumen de salida. Parameter Sharing contribuye a la invariancia de la traducción de la arquitectura CNN.\n",
    "\n",
    "\n",
    "Es importante notar que a veces la asunción de compartición de parámetros puede no tener sentido. Esto es especialmente el caso cuando las imágenes de entrada a una CNN tienen una estructura centrada específica, en la que esperamos que se aprendan características completamente diferentes en diferentes ubicaciones espaciales. Un ejemplo práctico es cuando la entrada son caras que han sido centradas en la imagen: podemos esperar que diferentes características específicas de ojo o cabello sean aprendidas en diferentes partes de la imagen. En ese caso, es común relajar el esquema de compartición de parámetros, y simplemente llamar a la capa una capa conectada localmente.\n",
    "\n",
    "2 .  Capa de agrupación\n",
    "\n",
    "\n",
    "Otro concepto importante de CNNs es el pooling, que es una forma de down-sampling no lineal. Existen varias funciones no lineales para implementar la agrupación entre las cuales la agrupación máxima es la más común. Divide la imagen de entrada en un conjunto de rectángulos que no se superponen y, para cada una de dichas subregiones, emite el máximo. La intuición es que una vez que una característica se ha encontrado, su ubicación exacta no es tan importante como su ubicación áspera en relación con otras características. La función de la capa de agrupación es reducir progresivamente el tamaño espacial de la representación para reducir la cantidad de parámetros y de cálculo en la red, y por lo tanto también para controlar el sobreensado. Es común insertar periódicamente una capa de agrupación entre capas sucesivas de conv en una arquitectura CNN. La operación de agrupación proporciona una forma de invariancia de traducción.\n",
    "\n",
    "La capa de agrupación funciona independientemente en cada segmento de profundidad de la entrada y la redimensiona espacialmente. La forma más común es una capa de agrupación con filtros de tamaño 2x2 aplicado con una zancada de 2 downsamples en cada rebanada de profundidad en la entrada por 2 a lo largo de ambos ancho y alto, descartando el 75% de las activaciones. En este caso, cada operación MAX tomaría un máximo de 4 números. La dimensión de profundidad no cambia.\n",
    "\n",
    "\n",
    "Además de la agrupación máxima, las unidades de agrupación también pueden realizar otras funciones, como la agrupación media e incluso la agrupación de normas $L_2$. La agrupación media se utilizó a menudo históricamente, pero recientemente ha caído en desgracia en comparación con la operación de agrupación máxima, que se ha comprobado que funciona mejor en la práctica.\n",
    "\n",
    "Debido a la reducción agresiva en el tamaño de la representación (que es útil sólo para conjuntos de datos más pequeños para controlar el sobreensado), la tendencia actual en la literatura es hacia el uso de filtros más pequeños  o descartar la capa de agrupación en conjunto.\n",
    "\n",
    "3 . Capa ReLU\n",
    "\n",
    "ReLU es la abreviatura de Rectified Linear Units. Esta es una capa de neuronas que aplica la función de activación no saturante f (x) = max (0, x). Aumenta las propiedades no lineales de la función de decisión y de la red global sin afectar los campos receptivos de la capa de convolución.\n",
    "\n",
    "\n",
    "Otras funciones también se usan para aumentar la no linealidad, por ejemplo la tangente hiperbólica saturante $f (x) = tanh ⁡ (x) , f (x) = \\vert Tanh ⁡ (x) \\vert $ , y la función sigmóide  $f (x) = (1 + e ^ {- x}) ^ {- 1}$. En comparación con otras funciones el uso de ReLU es preferible, ya que da lugar a la formación de red neural varias veces más rápido, sin hacer una diferencia significativa en la precisión de generalización.\n",
    "\n",
    "\n",
    "4 . Capa completamente conectada\n",
    "\n",
    "Finalmente, después de varias capas convolucionales y de agrupación máxima, el razonamiento de alto nivel en la red neuronal se realiza a través de capas completamente conectadas. Las neuronas en una capa completamente conectada tienen conexiones completas con todas las activaciones en la capa anterior, como se ve en las redes neuronales regulares. Por tanto, sus activaciones pueden calcularse con una multiplicación matricial seguida de un desplazamiento de polarización.\n",
    "\n",
    "5 . Capa de pérdida\n",
    "\n",
    "La capa de pérdida especifica cómo el entrenamiento en red penaliza la desviación entre las etiquetas predichas y verdaderas y es normalmente la última capa de la red. Pueden usarse varias funciones de pérdida apropiadas para diferentes tareas. La pérdida de Softmax se utiliza para predecir una sola clase de K clases mutuamente exclusivas. Se utiliza la pérdida de entropía cruzada sigmoidal para predecir valores de probabilidad independientes de K en $[0, 1]$. La pérdida euclidiana se utiliza para regresar a las etiquetas de valor real $[-\\infty, \\infty] .\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png \"Arquitectura basica\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Implementación\n",
    "\n",
    "### Previo\n",
    "\n",
    "\n",
    "MNIST es un simple conjunto de datos de visión artificial. Consiste en imágenes de dígitos manuscritos como estos:\n",
    "\n",
    "![alt text](https://www.tensorflow.org/versions/r0.10/images/MNIST.png \"mnist\")\n",
    "\n",
    "\n",
    "\n",
    "### Objetivos\n",
    "Comprar las tecnicas de reconocimiento de caracteres.\n",
    "\n",
    "\n",
    "\n",
    "### Entrada del modelo\n",
    "\n",
    "imagenes de 28 x 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
