{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades \n",
    "\n",
    "Referencia:\n",
    "\n",
    "1 . [Probability and Statistics for Computer Scientists](https://www.crcpress.com/Probability-and-Statistics-for-Computer-Scientists-Second-Edition/Baron/9781439875902) de Michael Baron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad como una forma de cuantificar la incertidumbre asociada con  eventos elegidos entre un universo de eventos. El universo se compone de todos los resultados posibles y cualquier subconjunto de estos resultados, es un evento; por ejemplo, \"el lanzamiento de un dado produce  un uno\" o \"el dado saca un número par.\"\n",
    "\n",
    "La notación `P(E)` significa \"la probabilidad del evento E\". \n",
    "\n",
    "Vamos a utilizar la teoría de probabilidades para construir modelos, para evaluar modelos, vamos a utilizar la teoría de probabilidades en todo momento. El siguiente enlace [Probability and Randomness in Games, Business and Life](https://www.youtube.com/watch?v=SVBgeol5kYQ&feature=youtu.be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencia e Independencia\n",
    "\n",
    "Dos eventos E y F son `dependientes`  cuando la ocurrencia o no-ocurrencia de uno de ellos afecta la probabilidad de ocurrencia del otro (o otros). De lo contrario, son independientes.\n",
    "\n",
    "Por ejemplo, si lanzamos una moneda dos veces, conociendo que  la primera lanzamiento es cara , no nos dá información sobre si el segundo lanzamiento es  cara . Estos eventos son independiente. Por otra parte, si el primer lanzamiento es cara  es sin duda nos da información acerca de que si los dos lanzamientos son cruz.  Estos dos eventos son dependientes.\n",
    "\n",
    "Matemáticamente, se dice que dos eventos E y F son independientes si la probabilidad de que ambos ocurran es el producto de las probabilidades de que cada uno ocurra:\n",
    "\n",
    "```tex\n",
    "P(E,F) = P(E)P(F)\n",
    "```\n",
    "\n",
    "En el ejemplo anterior, la  probabilidad de que 'el primer lanzamiento, resulta cara ' es `1/2` y la probabilidad de que 'ambas salgan cruz' es `1/4`, pero la probabilidad de que  'el primer lanzamiento resulte cara' y ambos 'lanzamientos cruces' es `0`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad Condicional\n",
    "\n",
    "Cuando dos eventos E y F son independientes, por definición tenemos:\n",
    "\n",
    "```\n",
    "P(E,F) = P(E)P(F)\n",
    "```\n",
    "Si ellos no son necesariamente independientes y asumiendo `P(F) > 0`, definimos la 'probabilidad condicional' de `E`, dado que `F` a ocurrido como sigue\n",
    "\n",
    "```tex\n",
    "P(E|F ) = P(E,F)/P(F)\n",
    "```\n",
    "\n",
    "Si E y F son independientes, se tiene que: `P(E|F) = P(E)`,  que es la forma matemática de expresar que el conocimiento de que si F ocurrió no nos da una información adicional acerca de que si se ha producido E.\n",
    "\n",
    "En general, no es el caso que `P(A|B) = P(B|A)`.\n",
    "\n",
    "La gente  confunde esto todo el tiempo, por ejemplo, la probabilidad de que tengas puntos (manchas)  dado que tienes  sarampión es 1, pero la probabilidad de que tienes  sarampión, dado que  tienes puntos (manchas) no es 1. En este caso, la diferencia entre `P(A|B)`  y `P(B|A)` es obvio, pero hay casos en los que es menos obvio. Este error se hace con bastante frecuencia en los casos legales que a veces se llama `falacia del fiscal` (ver el artículo [Ley y Probabilidad](http://www.uv.es/~montes/mat_omni/UIMP2003.pdf) de Francisco Montes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el siguiente problema: Sea una familia con dos hijos(sin saber). Si asumimos que:\n",
    "\n",
    "1 . Cada niño es igual de probable de ser un niño o niña.\n",
    "\n",
    "2 . El género del segundo niño es independiente del género del primer niño.\n",
    "\n",
    "\n",
    "Entonces el evento 'no  niñas' es `1/4`, el evento 'una niña, un niño'  tiene probabilidad `1/2` y el evento 'dos niñas' tiene una probabilidad de `1/4`.\n",
    "\n",
    "¿Cuál es la probabilidad de que ocurra el evento 'ambos niños, son niñas' (E), condicionado al evento 'el  niño de mayor es niña' (F)?. Usando probabilidad condicional}:\n",
    "\n",
    "```tex\n",
    "P(E|F) = P(E,F)/P(F) = P(E)/P(F) = 1/2\n",
    "```\n",
    "\n",
    "desde que los eventos E y F ('ambos niños son niñas el niño mayor es niña') es sólo el evento E.\n",
    "\n",
    "Pero que pasaria, si preguntamos ¿Cuál es la probabilidad de que ocurra el evento 'ambos niños, son niñas' (E), condicionado al evento 'el  menos uno de los niños es  niña' (G)?. \n",
    "\n",
    "Como antes los eventos E y G ('ambos niños son niñas  y al menos un niño  es niña') es sólo el evento E. Esto significa que  tenemos:\n",
    "\n",
    "```tex\n",
    "    P(E|G) = P(E,G)/P(G) = P(E)/P(G) = 1/3\n",
    "```\n",
    "\n",
    "y esto se debe a que, si lo único que sabe es que al menos uno de los niños es una niña, entonces es dos veces más probable que la familia tenga  un niño y una niña a que tenga dos niñas. \n",
    "\n",
    "Verifiquemos esto en Python, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(ambos | mayor): 0.5007089325501317\n",
      "P(ambos | si al menos un chico es chica):  0.3311897106109325\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo acerca de probabilidad condicional\n",
    "\n",
    "# Ejemplo acerca de la probabilidad condicional en Python\n",
    "\n",
    "import  random\n",
    "\n",
    "def random_kid():\n",
    "    return random.choice([\"chico\", \"chica\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ambos_chicas = 0\n",
    "    mayor_chica = 0\n",
    "    si_es_chica = 0\n",
    "\n",
    "    random.seed(0)\n",
    "    for _ in range(10000):\n",
    "        menor = random_kid()\n",
    "        mayor = random_kid()\n",
    "        if mayor == \"chica\":\n",
    "            mayor_chica += 1\n",
    "        if mayor == \"chica\" and menor == \"chica\":\n",
    "            ambos_chicas += 1\n",
    "        if mayor == \"chica\" or menor == \"chica\":\n",
    "            si_es_chica += 1\n",
    "\n",
    "    print(\"P(ambos | mayor):\", ambos_chicas / mayor_chica)      \n",
    "    print(\"P(ambos | si al menos un chico es chica): \", ambos_chicas / si_es_chica) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de Bayes \n",
    "\n",
    "\n",
    "En un artículo de Steven Strogatz llamado [Chances are](http://opinionator.blogs.nytimes.com/category/steven-strogatz/) en el diario New York Times se presenta el siguiente problema:\n",
    "\n",
    "```\n",
    "Se sabe el que 0.8% de las mujeres adultas pueden tener cancer de mamas. Si una mujer tiene cáncer de mamas, hay \n",
    "un 90% de chances que tenga un mamograma positivo. Si una mujer no tiene cáncer de mamas, todavía existe un\n",
    "7% de probabilidades que tenga un mamograma positivo. Si una mujer va al control anual y tiene su mamograma positivo, \n",
    "¿cuáles son las chances de que tenga cancer de mamas?\n",
    "```\n",
    "\n",
    "El problema nos brinda información suficiente para contestar la pregunta, sin embargo la misma no puede ser utilizada directamente, pues sabemos cuál es la probabilidad que una mujer con cáncer de mamas tenga un mamograma positivo, y se nos pregunta, en cambio, cuál es la probabilidad que una mujer tenga cáncer de mamas con un mamograma positivo. De alguna manera\n",
    "tenemos que dar vuelta los datos : si conocemos información sobre la ocurrencia de un evento E siempre que haya ocurrido un evento F, necesitamos saber si es posible inferir la ocurrencia del evento F siempre que haya ocurrido E. \n",
    "\n",
    "Este es el contenido del Teorema de Bayes.\n",
    "\n",
    "Utilizando la definición de Probabilidad Condicional dos veces, podemos tener:\n",
    "\n",
    "```\n",
    "P(E|F) = P(E,F)/P(F) = P(F|E)P(E)/P(F)\n",
    "```\n",
    "\n",
    "El evento F puede ser dividido en dos eventos  mutualmente exclusivos 'F y E' y 'F y no E'. Si escribimos '¬E' para 'no E (E no ocurre)', entonces\n",
    "\n",
    "```\n",
    "P(F) = P(F,E) + P(F,¬E)\n",
    "```\n",
    "\n",
    "Así que tenemos el Teorema de Bayes:\n",
    "\n",
    "```\n",
    "P(E|F) = P(F|E)P(E)/[P(F|E)P(E) + P(F|¬E)P(¬E)]\n",
    "```\n",
    "\n",
    "Una aplicación de esto son los [clasificadores bayesianos](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo) que son frecuentemente usados en implementaciones de filtros de correo basura o spam, que se adaptan con el uso que se verá más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Aleatorias\n",
    "\n",
    "Una variable aleatoria es una variable cuyos valores posibles tienen asociados  una distribución de probabilidad. Una variable aleatoria simple es igual a 1 si el lanzamiento de una moneda produce  cara y 0 si el lanzamiento sale cruz. Un ejemplo  más complicado podría ser medir  el número de caras  observados al lanzar una moneda 10 veces o un valor escogido desde `range(10)`, donde cada número tiene la misma probabilidad de salir.\n",
    "\n",
    "Una distribución de probabilidad  es una función que asigna a cada suceso definido sobre la variable aleatoria, la probabilidad de que dicho suceso ocurra. La variable del lanzamiento de una moneda es igual a 0 con probabilidad 0.5 y 1 con probabilidad 0.5. La variable `rango(10)` tiene una distribución de probabilidad que asigna 0.1 a cada uno de los números del 0 al 9.\n",
    "\n",
    "\n",
    "A veces vamos a hablar sobre el valor esperado (*expected value*) de una variable aleatoria, que es el promedio de los valores ponderados por sus probabilidades. La variable del lanzamiento de una moneda tiene un valor esperado de `1/2 (= 0* 1/2 + 1*1/2)`, y la variable `range(10` tiene un valor esperado de 4.5.\n",
    "\n",
    "Las variables aleatorias pueden estar condicionadas a eventos al igual que los eventos . Si regresamos al ejemplo de los dos hijos sobre  \"probabilidad condicional\" , si X es la variable aleatoria que representa 'el número de niñas', X es igual a 0 con una probabilidad de 1/4, 1 con probabilidad 1/2 y 2 con una probabilidad de 1/4.\n",
    "\n",
    "Podemos definir una nueva variable aleatoria Y que da el número de niñas condicionada a que al menos uno de los niños es  una niña. Entonces Y es igual a 1 con una probabilidad de 2/3 y 2 con una probabilidad de 1/3 y una variable Z que es el número de niñas condicionada a que el  niño mayor sea una chica es igual a 1 con probabilidad 1/2 y 2 con probabilidad 1/2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Por ejemplo, [scipy](http://www.scipy.org/) contiene módulos que contienen un gran número de distribuciones de probabilidad, así como también una creciente librería de funciones estadísticas llamada [scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html#discrete-distributions). Tomemos un ejemplo de la documentación de Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distribucion Binomial usando scipy.stats\n",
    "\n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# Calculamos los primeros momentos:\n",
    "\n",
    "n, p = 5, 0.4\n",
    "mean, var, skew, kurt = binom.stats(n, p, moments='mvsk')\n",
    "\n",
    "# Mostramos el pmf de la variable aleatoria  (``pmf``):\n",
    "\n",
    "x = np.arange(binom.ppf(0.01, n, p),\n",
    "              binom.ppf(0.99, n, p))\n",
    "ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='pmf Binomial')\n",
    "ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\n",
    "ax.legend(loc='best', frameon=False)\n",
    "\n",
    "\n",
    "# Comprobar la exactitud del  ``cdf`` y  ``ppf``:\n",
    "\n",
    "prob = binom.cdf(x, n, p)\n",
    "np.allclose(x, binom.ppf(prob, n, p))\n",
    "\n",
    "\n",
    "# Generamos numeros aleatorios\n",
    "\n",
    "r = binom.rvs(n, p, size=1000)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un lanzamiento de moneda corresponde a una distribución discreta, esto es una  que asocia una  probabilidad positiva con resultados discretos. A menudo vamos a querer modelar distribuciones a través de una serie continua de los resultados.\n",
    "(estos resultados serán siempre los números reales, aunque eso no se da siempre el caso en la vida real).\n",
    "\n",
    "Podemos representar una distribución continua con  una  función de densidad de probabilidad, función de densidad, que  describe la probabilidad relativa según la cual dicha distribución tomará determinado valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## La distribución Normal\n",
    "\n",
    "Una de las distribuciones más importantes de la teoria de las Probabilidades es la `distribución normal`, determinada completamente determinada por dos parámetros: su media ($\\mu$) y su desviación estándar ($\\sigma$). La media indica donde la distribución es centrada y la desviación estándar cuán 'ancha' es. La distribución normal tiene la forma:\n",
    "\n",
    "$$ \n",
    "f(x | \\mu, \\sigma) =  \\frac{1}{\\sqrt{2\\pi}\\sigma} exp\\biggl(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\biggr)\n",
    "$$\n",
    "Que se implementa en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normal_pdf(x, mu=0, sigma=1):\n",
    "    sqrt_two_pi = math.sqrt(2 * math.pi)\n",
    "    return (math.exp(-(x-mu) ** 2 / 2 / sigma ** 2)/ (sqrt_two_pi * sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Mostremos algunos gráficos de las funciones de densidad, para distintos valores de la media y desviación estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "xs = [x / 10.0 for x in range(-50, 50)]\n",
    "plt.plot(xs,[normal_pdf(x,sigma=1) for x in xs],'-',label='mu=0,sigma=1')\n",
    "plt.plot(xs,[normal_pdf(x,sigma=2) for x in xs],'--',label='mu=0,sigma=2')\n",
    "plt.plot(xs,[normal_pdf(x,sigma=0.5) for x in xs],':',label='mu=0,sigma=0.5')\n",
    "plt.plot(xs,[normal_pdf(x,mu=-1) for x in xs],'-.',label='mu=-1,sigma=1')\n",
    "plt.legend()\n",
    "plt.title(\"Varias funciones de densidad  para la distribucion Normal \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cuando $\\mu = 0$ y $\\sigma = 1$, la distribución normal se conoce como, **distribución normal estándar**. Si `Z` es una distribución normal estándar, entonces resulta que:\n",
    "\n",
    "$$X = \\sigma Z + \\mu$$\n",
    "\n",
    "es también normal, pero con media $\\mu$ y desviación estándar $\\sigma$. Por otro lado, si $X$ es una variable aleatoria normal con media  $\\mu$ y desviación estándar $\\sigma$,\n",
    "\n",
    "$$Z = (X -\\mu)/\\sigma$$\n",
    "\n",
    "es una variable normal estándar. La función de distribución acumulativa (CDF), no puede ser escrita de manera 'elemental', pero puede ser escrita usando `math.erf`, que retorna la [función error](https://en.wikipedia.org/wiki/Error_function):\n",
    "\n",
    "$$F(x) = \\frac{1}{2}\\biggl[1 + erf\\biggl( \\frac{x - \\mu}{\\sqrt{2}\\sigma}\\biggr)\\biggr]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def normal_cdf(x, mu=0,sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra vez mostremos los gráficos de  algunas  CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "xs = [x / 10.0 for x in range(-50, 50)]\n",
    "plt.plot(xs,[normal_cdf(x,sigma=1) for x in xs],'-',label='mu=0,sigma=1')\n",
    "plt.plot(xs,[normal_cdf(x,sigma=2) for x in xs],'--',label='mu=0,sigma=2')\n",
    "plt.plot(xs,[normal_cdf(x,sigma=0.5) for x in xs],':',label='mu=0,sigma=0.5')\n",
    "plt.plot(xs,[normal_cdf(x,mu=-1) for x in xs],'-.',label='mu=-1,sigma=1')\n",
    "plt.legend(loc=4) \n",
    "plt.title(\"Varias  cdfs de la distribución normal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces tendremos que invertir `normal_cdf` para encontrar el valor correspondiente a una probabilidad específica(funcion cuantil). No hay manera fácil de calcular su inversa, pero  `normal_cdf` es  continua y estrictamente creciente, por lo que podemos utilizar  `búsqueda binaria` *(Joel Grus-Data Science from Scratch: First Principles with Python)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inversa_normal_cdf(p, mu=0, sigma=1, tolerancia=0.00001):\n",
    "    \n",
    "    \"\"\"encuentra aproximadamente la inversa de CDF usando busqueda binaria\"\"\"\n",
    "    \n",
    "    # si no es estándar, calculamos el estándar y reescalamos\n",
    "    \n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerancia=tolerancia)\n",
    "    l_z, l_p = -10.0, 0 # normal_cdf(-10) es (muy cerca a) 0\n",
    "    h_z, h_p = 10.0, 1 # normal_cdf(10) es (muy cerca a) 1\n",
    "    \n",
    "    while h_z - l_z > tolerancia:\n",
    "        medio_z = (l_z + h_z) / 2 # consideramo el punto medio\n",
    "        mid_p = normal_cdf(medio_z) # y el valor cdf's existe\n",
    "        if medio_p < p:\n",
    "            #  el punto medio es aun muy bajo, buscamos arriba \n",
    "            l_z, l_p = medio_z, medio_p\n",
    "        elif medio_p > p:\n",
    "            \n",
    "            # el punto medio es muy alto, busco \n",
    "            h_z, h_p = medio_z, medio_p\n",
    "        else:\n",
    "            break\n",
    "    return medio_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función repetidamente biseca un intervalo, hasta que se acerca en un Z que es lo suficiente cerca a la probabilidad deseada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ley de los Grandes Números\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El teorema del Límite Central \n",
    "\n",
    "Una de las razones por la que la  distribución normal es tan útil, proviene del teorema del límite central, que\n",
    "dice (en esencia) que una variable aleatoria definida como el promedio de un gran número de variables aleatorias independientes e idénticamente distribuidas es en sí misma aproximadamente  una distribución normal.\n",
    "\n",
    "\n",
    "En particular, si $x_1,\\dots , x_n $ son variables aleatorias con media $\\mu$ y desviación estándar $\\sigma$,\n",
    "y si $n$ es grande, entonces:\n",
    "\n",
    "$$\\frac{1}{n}\\bigl(x_1 + \\cdots x_n\\bigr)$$\n",
    "\n",
    "es aproximadamente una distribución normal con media $\\mu$ y desviación estándar  $\\sigma /\\sqrt{n}$. Equivalentemente:\n",
    "\n",
    "$$\\frac{\\bigl(x_1 + \\cdots +x_n \\bigr)}{\\sigma\\sqrt{n}}$$\n",
    "\n",
    "es aproximadamente una distribución normal con media `0` y desviación estándar `1`.\n",
    "\n",
    "Una manera de ver este resultado, es a través de las variables aleatorias binomiales, las cuales tienen dos parámetros $n$ y $p$. Una variable aleatoria `Binomial(n,p)` es simplemente la suma de $n$ variables aleatorias Bernoulli independientes `Bernoulli(p)` cada uno de los cuales es igual a `1` con probabilidad `p` y `0` con probabilidad `1 - p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, collections \n",
    "\n",
    "def bernoulli_prueba(p):\n",
    "    return 1 if random.random() < p else 0\n",
    "\n",
    "def binomial(n,p):\n",
    "    return sum(bernoulli_prueba(p) for _ in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media de una variable `Bernoulli(p)` es $p$ y su desviación estándar es $\\sqrt{p(1 -p)}$. El teorema del Límite Central dice que cuando $n$ es muy grande, una variable `Binomial(n ,p)` es aproximadamente una variable aleatoria normal con media $\\mu = np$ y desviación estándar $\\sigma = \\sqrt{np(1 -p)}$. Veamos un gráfico que muestra este resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def bernoulli_prueba(p):\n",
    "    return 1 if random.random() < p else 0\n",
    "\n",
    "def binomial(n,p):\n",
    "    return sum(bernoulli_prueba(p) for _ in range(n))\n",
    "    \n",
    "\n",
    "def normal_cdf(x, mu=0,sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "\n",
    "def graf_histograma(p, n, num_puntos):\n",
    "    data = [binomial(n, p) for _ in range(num_puntos)]\n",
    "\n",
    "    # usamos un grafico de barras para mostrar las muestras binomiales\n",
    "    histograma  = Counter(data)\n",
    "    plt.bar([x - 0.4 for x in histograma .keys()],\n",
    "            [v / num_puntos for v in histograma .values()],\n",
    "            0.8,\n",
    "            color='0.75')\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(n * p * (1 - p))\n",
    "    # usamos un grafico de  lineas para mostrar una  aproximacion normal\n",
    "    xs = range(min(data), max(data) + 1)\n",
    "    ys = [normal_cdf(i + 0.5, mu, sigma) - normal_cdf(i - 0.5, mu, sigma)\n",
    "          for i in xs]\n",
    "    plt.plot(xs,ys)\n",
    "    plt.title(\"Distribucion Binomial vs. Approximacion Normal\")\n",
    "    plt.show()\n",
    "    \n",
    "# graf_histograma(0.75, 100, 10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html) es módulo de la libreria científica Scipy que  contiene un gran número de distribuciones de probabilidad, así como una creciente biblioteca de funciones estadísticas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[animation](http://yihui.name/animation/) es un paquete de R para crear y exportar animaciones a una variedad de formatos (HTML / JS, GIF, vídeo, PDF), así como una galería de animaciones estadísticas, como muestra el siguiente ejemplo, acerca del teorema del Límite Central de la documentación de animation de Yuihui Xie\n",
    "\n",
    "```R\n",
    "library(animation)\n",
    "\n",
    "saveHTML({\n",
    "  par(mar = c(3, 3, 1, 0.5), mgp = c(1.5, 0.5, 0), tcl = -0.3)\n",
    "  ani.options(interval = 0.1, nmax = ifelse(interactive(), 150, 10))\n",
    "  clt.ani(type = \"h\")\n",
    "}, img.name = \"clt.ani\", htmlfile = \"clt.ani.html\", ani.height = 500,\n",
    "ani.width = 600, title = \"Demonstracion del teorema del Limite Central\",\n",
    "description = c(\"Esta animación muestra la distribución de la muestra \",\n",
    "                  \" significa que el tamaño de la muestra crece.\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
