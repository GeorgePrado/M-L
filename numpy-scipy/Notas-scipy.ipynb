{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy : Librería Cientifica de Python\n",
    "\n",
    "Características:  \n",
    "\n",
    "1. Utiliza [Numpy](http://www.numpy.org/).\n",
    "2. Es que posee una gran cantidad de módulos para diversas áreas científicas:\n",
    "  * Algebra Lineal.\n",
    "  * Modelamiento y fijado de datos.\n",
    "  * Optimización\n",
    "  * Procesamiento de Imaǵenes.\n",
    "  * Estadistica y Probabilidades\n",
    "  * Clusters\n",
    "  * ....\n",
    "  \n",
    "  Mayor información en [la documentación de Scipy](https://www.scipy.org/getting-started.html).\n",
    "  \n",
    " 3 . Scipy no tiene módulos de Analisis Bayesiano, es decir no tiene capacidades para **MCMC (Markov Chain Monte Carlo)**, pero existen otras alternativas como [PyMC](https://github.com/pymc-devs/pymc).\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración \n",
    "\n",
    "En Scipy el principal propósito de la .integración es obtener soluciones numéricas.\n",
    "\n",
    "Calculemos como ejemplo: $$ \\int_{0}^3 \\cos^2(e^x) \\ dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.296467785724373, 1.3977971863744082e-09)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Defininamos la funcion a integrar\n",
    "\n",
    "func = lambda x: np.cos(np.exp(x))**2\n",
    "\n",
    "# Integrar la función con los limites 0 y 3 respectivamente\n",
    "\n",
    "solucion = quad(func, 0,3)\n",
    "print(solucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer elemto es el valor deseado y el segundo es el error  en el ejemplo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: Calcula lo siguiente $$\\int_{0}^{1}\\sin(x^2)\\ dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración Numérica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsolucion = 5.100345067540932\n",
      "dsolucion = 5.08425628579\n",
      " La diferencia entre estos dos metodos es 0.0160887817531\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad, trapz\n",
    "\n",
    "# Colocando los datos simulados (fake dates )\n",
    "\n",
    "x = np.sort(np.random.randn(150)*4 + 4).clip(0,5)\n",
    "func = lambda x: np.sin(x) *np.cos(x ** 2) + 1 \n",
    "y = func(x)\n",
    "\n",
    "# Itegrando desde los limites : 0 y 5\n",
    "fsolucion = quad(func, 0, 5)\n",
    "dsolucion = trapz(y, x =x)\n",
    "\n",
    "print(\"fsolucion = \" + str(fsolucion[0]))\n",
    "print(\"dsolucion = \" +  str(dsolucion))\n",
    "\n",
    "print(\" La diferencia entre estos dos metodos es \" \\\n",
    "      +  str(np.abs(fsolucion[0] -dsolucion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy para data mining (mineria de datos)\n",
    "\n",
    "Módulos a usar:\n",
    "\n",
    "- `scipy.stats`: módulo de herramientas estadísticas\n",
    "- `scipy.ndimage.measurements`: módulo  de análisis y organización  de datos.\n",
    "- `scipy.spatial`.\n",
    "- `scipy.cluster`\n",
    "\n",
    "El paquete `scipy.cluster` consiste de dos módulos: `scipy.cluster.vq` y `scipy.cluster.hierarchy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cuantización de Vector (VQ)\n",
    "\n",
    "Es un término que está asociado con el procesamiento de señales compresión de datos y clustering. En este ejemplo nos vamos a centrar en la cuantización de vector como  componente clustering empezando con llenar de datos al paquete VQ de manera de identificar los cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster import vq\n",
    "\n",
    "# Creando datos\n",
    "\n",
    "c1 = np.random.randn(100, 2) + 5\n",
    "c2 = np.random.randn(30, 2) - 5\n",
    "c3 = np.random.randn(50,2)\n",
    "\n",
    "# Creando una matriz para juntar datos (array de 180x2)\n",
    "\n",
    "data = np.vstack([c1, c2, c3])\n",
    "\n",
    "# Calculando el centroide del cluster  y la varianza desde k-means\n",
    "\n",
    "centroide, varianza = vq.kmeans(data, 3)\n",
    "\n",
    "# Separando los puntos en el cluster basados en la funcion vq\n",
    "\n",
    "identi, distancia = vq.vq(data, centroide)\n",
    "\n",
    "# Recuperando las coordenadas para los puntos en cada vq\n",
    "\n",
    "vqc1 = data[identi == 0]\n",
    "vqc2 =data[identi == 1]\n",
    "vqc3 = data[identi == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13303675, -0.05277057],\n",
       "       [ 4.94743764,  5.11416207],\n",
       "       [-4.90125862, -4.98656738]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1973866595112574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60118434, -1.40228847],\n",
       "       [ 0.21340528, -1.93385529],\n",
       "       [-0.45166722, -0.53299176],\n",
       "       [-0.93181297,  0.43310475],\n",
       "       [-0.67424634, -0.09126108],\n",
       "       [ 0.63185292, -0.9356187 ],\n",
       "       [ 0.44379495,  1.06023639],\n",
       "       [ 0.54816535, -0.9316109 ],\n",
       "       [ 1.14808018, -2.71156065],\n",
       "       [ 0.02479205,  2.31613159],\n",
       "       [ 0.21447867,  1.821523  ],\n",
       "       [ 0.37743134,  0.04478592],\n",
       "       [-1.22752463,  1.13916886],\n",
       "       [ 0.47108522,  1.78837662],\n",
       "       [-0.21779439,  0.17070855],\n",
       "       [ 1.31797411,  1.80874521],\n",
       "       [-0.27648544, -1.09621865],\n",
       "       [-1.75380668,  0.37980429],\n",
       "       [ 0.53669507, -0.72063633],\n",
       "       [-0.82949971, -1.03639442],\n",
       "       [-2.03820997, -0.91392883],\n",
       "       [-0.49153928,  1.10783514],\n",
       "       [ 1.35527378, -1.12522855],\n",
       "       [-0.08264612, -0.23292068],\n",
       "       [ 1.51232234, -0.96244094],\n",
       "       [ 0.84480294,  1.33128031],\n",
       "       [ 0.17392695, -1.55114604],\n",
       "       [ 0.05472991, -1.77314172],\n",
       "       [ 0.67670017, -0.40218001],\n",
       "       [ 0.67776005,  0.0051569 ],\n",
       "       [ 0.2501    , -0.98578302],\n",
       "       [ 0.58510575,  0.47736343],\n",
       "       [-0.63089329,  0.80946142],\n",
       "       [ 0.3060593 ,  0.48164945],\n",
       "       [ 0.1681143 ,  0.85218737],\n",
       "       [ 1.98080686, -0.60642267],\n",
       "       [ 0.57622679,  1.25487741],\n",
       "       [ 0.08037595, -2.17297642],\n",
       "       [ 1.23644418, -0.60096405],\n",
       "       [ 0.2874407 ,  0.69177102],\n",
       "       [-0.0875665 ,  1.57345347],\n",
       "       [ 1.79721908, -0.48530601],\n",
       "       [-0.20488621,  1.22499642],\n",
       "       [ 0.47871498,  0.08165111],\n",
       "       [-1.11448659, -0.55955531],\n",
       "       [-0.66945497, -0.61741342],\n",
       "       [ 0.29457561, -0.7235637 ],\n",
       "       [-0.61550782,  1.39914044],\n",
       "       [ 0.15355831,  0.26624081]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jerarquía de clusters\n",
    "\n",
    "Clustering es una técnica de data minning, cuyo proceso consiste en la división de datos en grupos de objetos similares. Cuando se representan la información obtenida a través de clusters se pierden algunos detalles de los datos, pero a la vez se simplifica dicha información.\n",
    "\n",
    "Las técnicas de Clustering son las que utilizando algoritmos matemáticos se encargan de agrupar objetos. Usando la información que brindan las variables que pertenecen a cada objeto se mide la similitud entre los mismos, y una vez hecho esto se colocan en clases que son muy similares internamente (entre los miembros de la misma clase) y a la vez diferente entre los miembros de las diferentes clases. \n",
    "\n",
    "Un algoritmo importante se llama k-means:\n",
    "\n",
    "Este algoritmo debe definir el número de clusters que se desean obtener, así se convierte en un algoritmo voraz para particionar. Este algoritmo funciona de la siguiente manera: primeramente se determina la cantidad de clusters en los que se quiere agrupar la información, en este caso las simulaciones. Luego se asume de forma aleatoria los centros por cada clusters. Una vez encontrados los primeros centroides el algoritmo hará los tres pasos siguientes:\n",
    "\n",
    "1 . Determina las coordenadas del centroide.\n",
    "\n",
    "2 . Determina la distancia de cada objeto a los centroides.\n",
    "\n",
    "3 .Agrupa los objetos basados en la menor distancia.\n",
    "\n",
    "\n",
    "\n",
    "Es una herramienta para identificar estructuras que están anidadas dentro de otras grandes estructuras. Hagamos un ejemplo para generar un sistema múltiple de cluster. Para emplear la función (hierarchy) que permite esto, hay que construir la MATRIZ DISTANCIA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy.cluster.hierarchy as hy\n",
    "\n",
    "# Creando un cluster de una funcion clusters\n",
    "\n",
    "def clusters(numbers = 20, cnumber = 5, csize  = 10):\n",
    "    \n",
    "    rnum  =np.random.rand(cnumber, 2)\n",
    "    rn =rnum[:, 0] * numbers\n",
    "    rn = rn.astype(int)\n",
    "    rn[np.where(rn < 5)] = 5\n",
    "    rn[np.where(rn > numbers/2.0)] = round(numbers/2., 0)\n",
    "    ra = rnum[:, 1] * 2.9\n",
    "    ra[np.where(ra < 1.5)]  =1.5\n",
    "    \n",
    "    cls = np.random.rand(numbers, 3) * csize\n",
    "    \n",
    "# Multiplicadores aleatorios para puntos centrales del cluster\n",
    "\n",
    "    rxyz = np.random.rand(cnumber - 1, 3)\n",
    "    for i in range(cnumber - 1):\n",
    "        tmp = np.random.rand(rn[i +1], 3)\n",
    "    \n",
    "        x = tmp[:, 0] + (rxyz[i, 0] * csize)\n",
    "        y = tmp[:, 1] + (rxyz[i, 1] * csize)\n",
    "        z = tmp[:, 2] + (rxyz[i, 2] * csize)\n",
    "    \n",
    "        tmp = np.column_stack([x ,y, z])\n",
    "        cls = np.vstack([cls, tmp])\n",
    "\n",
    "    return cls\n",
    "\n",
    "# Generamos un cluster de cluster y la matriz distancia\n",
    "\n",
    "cls = clusters()\n",
    "D = pdist(cls [:, 0:2])\n",
    "D = squareform(D)\n",
    "# Calculamos y dibujamos nuestro primer dendrograma\n",
    "    \n",
    "fig = mpl.figure(figsize=(8,8))\n",
    "ax1 = fig.add_axes([0.09, 0.1, 0.2, 0.6])\n",
    "Y1 = hy.linkage(D, method = 'complete')\n",
    "cutoff = 0.3 *np.max(Y1[:,2])\n",
    "Z1 = hy.dendrogram(Y1,  orientation = 'right', color_threshold =cutoff)\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "\n",
    "# Calculemos y dibujemos el segundo dendrograma\n",
    "ax2 = fig.add_axes([0.3, 0.71, 0.6, 0.2])\n",
    "Y2 = hy.linkage(D, method = 'average')\n",
    "cutoff = 0.3 *np.max(Y2[:,2])\n",
    "Z2 = hy.dendrogram(Y2,  color_threshold =cutoff)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "\n",
    "    \n",
    "# Graficando la matriz distancia\n",
    "\n",
    "ax3 = fig.add_axes([0.3, 0.1, 0.6, 0.6])\n",
    "idx1 = Z1['leaves']\n",
    "idx2 = Z2['leaves']\n",
    "D = D[idx1,:]\n",
    "D = D[:, idx2]\n",
    "ax3.matshow(D, aspect = 'auto', origin = 'lower', cmap = mpl.cm.YlGnBu)\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)\n",
    "    \n",
    "# Colores\n",
    "\n",
    "fig.savefig('clusterq.pdf', bbox ='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelamiento de datos y ajustes\n",
    "\n",
    "Hya varias maneras de 'fijar datos' con una regresión lineal.  En esta parte usaremos `curve_fit` que un método $\\chi^2$. En el ejemplo a mostrar vamos a generar data desde una funcion conocida y ajustaremos con `curve_fit`. La función que usaremos como modelo es una función lineal $ f(x) = ax +b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9869579   2.03344083]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Creando una función  para modelar y crear datos\n",
    "\n",
    "def func(x, a,b):\n",
    "    return  a*x + b\n",
    "\n",
    "# Generando datos 'clean'\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = func(x, 1, 2)\n",
    "\n",
    "#  Agregando informacion('noise') a la data\n",
    "\n",
    "yn = y + 0.2 *np.random.normal(size = len(x))\n",
    "\n",
    "# Ejecutar curve_fit sobre los datos\n",
    "# popt devueleve los mejores valores ajustados\n",
    "# por los parametros del modelo dado\n",
    "\n",
    "popt, pcov =curve_fit(func, x, yn)\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede hacer ajustes a funciones no lineales como\n",
    "\n",
    "$$\n",
    "a * \\exp \\Bigl(\\dfrac{-(x -\\mu)^2}{2\\sigma^2}\\Bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40163867  0.1935454  -0.06530845]\n"
     ]
    }
   ],
   "source": [
    "#  Creando una función para modelar los datos creados\n",
    "\n",
    "def func(x, a, b,c ):\n",
    "    return a*np.exp(-(x -b)**2/(2*c**2))\n",
    "\n",
    "# Generando datos 'clean'\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = func(x, 1, 5,  2)\n",
    "\n",
    "#  Agregando informacion('noise') a la data\n",
    "\n",
    "yn = y + 0.2 *np.random.normal(size = len(x))\n",
    "\n",
    "# Ejecutar curve_fit sobre los datos\n",
    "# popt devueleve los mejores valores ajustados\n",
    "# por los parametros del modelo dado\n",
    "\n",
    "popt, pcov =curve_fit(func, x, yn)\n",
    "\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices Sparse \n",
    "\n",
    "¿ Qué pasaría si queremos manejar matrices de $10^{10}$ elementos?.\n",
    "\n",
    "Si la matriz tiene muchos ceros, entonces es posible manejar de manera eficiente este tipo de matriz, que es llamada Sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El array de NUmpy tiene720000 bytes\n",
      "El matriz sparse tiene7200 bytes\n",
      "La operaciones no-sparse toman0.522segundos \n",
      "La operaciones sparse toman0.068segundos \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from  scipy.sparse.linalg import eigsh\n",
    "from  scipy.linalg import eigh\n",
    "import scipy.sparse\n",
    "import time\n",
    "\n",
    "N = 300\n",
    "#  Creamos una matriz aleatoria de tipos sparse\n",
    "\n",
    "m = scipy.sparse.rand(N,N)\n",
    "                     \n",
    "a = m.toarray() # clon de Numpy para m\n",
    "                      \n",
    "print(\"El array de NUmpy tiene\"  + str(a.nbytes) + ' bytes')\n",
    "print(\"El matriz sparse tiene\"  + str(m.data.nbytes) + ' bytes')\n",
    "\n",
    "# No-sparse\n",
    "\n",
    "t0 = time.time()\n",
    "res1 = eigh(a)\n",
    "dt = str(np.round(time.time() -t0, 3)) + 'segundos '\n",
    "print(\"La operaciones no-sparse toman\" + dt)\n",
    "\n",
    "# sparse\n",
    "\n",
    "t0 = time.time()\n",
    "res1 = eigsh(m)\n",
    "dt = str(np.round(time.time() -t0, 3)) + 'segundos '\n",
    "print(\"La operaciones sparse toman\" + dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Estadística \n",
    "\n",
    "Numpy tiene  las funciones básicas de la estadística `mean`, `std`, `median`, `argmin` y `argmax ` , sin embargo  `numpy.arrays` tiene métodos construidos para las más importantes aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejemplo de estadística\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Construyamos un array aleatorio con 1000 elementos\n",
    "\n",
    "x = np.random.rand(10000)\n",
    "\n",
    "# Calcular varios métodos estadísticos que Numpy tiene\n",
    "\n",
    "mean = x.mean()\n",
    "std = x.std()\n",
    "var = x.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50142838297184589"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2854488682881513"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081481056406986357"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy contiene en el módulo [scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html) una extensa colección de herramientas para la estadistica y las probabilidades. como es el caso de las distribuciones continuas, discretas y multivariadas. \n",
    "\n",
    "Cuando llamamos a distribución desde `scipy.stats`, podemos extraer información de varias maneras: PDF, CDF, RVS. \n",
    "\n",
    "$$\n",
    "PDF = e^{(-x^2/2)/\\sqrt{2\\pi}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ejemplo de probabilidades: PDF de la RV normal\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Rango de la muestra a tomar\n",
    "\n",
    "x = np.linspace(-5, 5, 100000)\n",
    "\n",
    "# Colocando los parametros para la distribucion normal\n",
    "\n",
    "dist = norm( loc = 0, scale = 1)\n",
    "\n",
    "# Recuperando PDF y CDF de la distribucion normal\n",
    "\n",
    "pdf = dist.pdf(x)\n",
    "cdf = dist.cdf(x)\n",
    "\n",
    "# Recupperando RVS ( Muestreo de la variable aleatoria)\n",
    "muestreo = dist.rvs(500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.48671951e-06,   1.48746306e-06,   1.48820696e-06, ...,\n",
       "         1.48820696e-06,   1.48746306e-06,   1.48671951e-06])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.86651572e-07,   2.86800282e-07,   2.86949067e-07, ...,\n",
       "         9.99999713e-01,   9.99999713e-01,   9.99999713e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ejercicio: Hallar mediante `scipy.stats` el PMF, CDF y RVS de la distribución geométrica, cuyo PMF es\n",
    " \n",
    " $$\n",
    " PMF = (1 -p)^{k -1}p\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import geom\n",
    "\n",
    "# Parametros de la distribucion geometrica\n",
    "\n",
    "p = 0.5\n",
    "dist = geom(p)\n",
    "\n",
    "# rango de valores \n",
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "# Recuperando PDF y CDF de la distribucion normal\n",
    "pmf = dist.pmf(x)\n",
    "cdf = dist.cdf(x)\n",
    "\n",
    "# Recupperando RVS ( Muestreo de la variable aleatoria)\n",
    "muestreo = dist.rvs(500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  1,  1,  3,  2,  1,  1,  3,  2,  1,  4,  1,  4,  1,  4,  1,\n",
       "        2,  1,  1,  1,  1,  2,  1,  1,  2,  2,  1,  2,  2,  2,  1,  1,  1,\n",
       "        1,  7,  4,  2,  1,  3,  1,  1,  6,  3,  3,  1,  5,  6,  1,  2,  2,\n",
       "        1,  1,  1,  1,  3,  1,  3,  1,  1,  3,  1,  1,  3,  2,  2,  1,  1,\n",
       "        1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,\n",
       "        1,  5,  3,  1,  1,  1,  1,  4,  2,  1,  2,  1,  1,  1,  1,  3,  1,\n",
       "        3,  3,  8,  2,  2,  7,  1,  2,  2,  1,  3,  4,  1,  3,  4,  1,  3,\n",
       "        2,  2,  2,  1,  1,  2,  1,  3,  1,  1,  4,  1,  8,  3,  1,  1,  2,\n",
       "        5,  2,  2,  3,  3,  3,  4,  1,  1,  1,  2,  1,  2,  1,  1,  1,  1,\n",
       "        3,  1,  1,  3,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,\n",
       "        2,  1,  1,  3,  1,  1,  2,  2,  3,  2,  2,  2,  1,  3,  1,  1,  2,\n",
       "        2,  1,  1,  4,  2,  7,  5,  2,  1,  1,  3,  1,  1,  2,  1,  2,  4,\n",
       "        2,  2,  5,  2,  1,  1,  3,  2,  1,  1,  3,  2,  1,  1,  2,  2,  1,\n",
       "        5,  1,  2,  2,  1,  5,  2,  1,  3,  1,  1,  2,  2,  2,  1,  5,  1,\n",
       "        3,  3,  1,  1, 14,  1,  3,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,\n",
       "        1,  1,  4,  1,  5,  1,  1,  1,  2,  2,  1,  2,  1,  5,  4,  1,  1,\n",
       "        1,  2,  3,  4,  2,  1,  8,  2,  4,  2,  2,  2,  1,  1,  2,  1,  1,\n",
       "        1,  1,  3,  1,  1,  4,  1,  2,  2,  2,  4,  1,  1,  2,  1,  2,  1,\n",
       "        1,  1,  4,  1,  1,  1,  1,  5,  1,  1,  5,  1,  1,  4,  1,  7,  1,\n",
       "        1,  1,  3,  1,  1,  1,  1,  3,  2,  3,  6,  3,  1,  3,  1,  2,  1,\n",
       "        2,  1,  2,  1,  1,  2,  1,  2,  1,  1,  2,  2,  1,  1,  1,  3,  5,\n",
       "        2,  1,  1,  1,  3,  1,  2,  1,  1,  1,  4,  1,  1,  1,  7,  4,  1,\n",
       "        1,  3,  1,  3,  2,  2,  1,  1,  1,  3,  1,  3,  4,  3,  3,  2,  2,\n",
       "        1,  1,  1,  1,  2,  1,  1,  2,  2,  1,  1,  1,  1,  1,  5,  1,  1,\n",
       "        1,  3,  4,  1,  1,  1,  1,  2,  3,  2,  4,  1,  4,  1,  2,  1,  2,\n",
       "        1,  3,  3,  2,  7,  1,  2,  2,  1,  5,  1,  3,  1,  4,  1,  1,  2,\n",
       "        1,  2,  1,  2,  1,  1,  2,  1,  2,  2,  2,  2,  1,  2,  1,  1,  1,\n",
       "        1,  1,  1,  1,  2,  2,  2,  1,  1,  1,  1,  1,  2,  1,  1,  2,  1,\n",
       "        1,  2,  1,  5,  1,  4,  2,  1,  1,  4,  1,  1,  1,  1,  3,  1,  3,\n",
       "        4,  1,  2,  1,  1,  1,  2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
